{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ba262c",
   "metadata": {},
   "source": [
    "# Tender Material Generator\n",
    "This notebook fetches any assortment in scope based on provided filtering.\n",
    "The notebook prepares and cleans the data, before loading it into a data frame.\n",
    "The notebook will provide the user with summary statistics and key insights for internal usage.\n",
    "The notebook generates a .csv file suitable for external sharing when doing RFX-processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99270c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from scipy.stats import mode\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import parameters\n",
    "import source.data_processing.clustering_params as params\n",
    "from datetime import datetime\n",
    "\n",
    "# Import the new clustering pipeline\n",
    "try:\n",
    "    from source.data_processing.clustering_pipeline import (\n",
    "        ClusteringPipeline\n",
    "    )\n",
    "    print(\"Successfully imported ClusteringPipeline\")\n",
    "except SyntaxError as e:\n",
    "    print(f\"Syntax error in clustering_pipeline.py: {e}\")\n",
    "    print(\"Please check line 29 in clustering_pipeline.py for syntax issues\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "\n",
    "# Import functions for data fetching and cleaning\n",
    "from source.data_processing.analysis_utils import (\n",
    "    fetch_tender_material,\n",
    "    pivot_attributes_wide,\n",
    "    fetch_distinct_values,\n",
    "    apply_df_filters,\n",
    ")\n",
    "\n",
    "# import functions to visualize and analyze clustering results\n",
    "from source.data_processing.clustering_visualization_utils import (\n",
    "    build_totals,\n",
    "    plot_overall_cluster_metrics,\n",
    "    plot_yearly_trends,\n",
    "    plot_feature_scatter,\n",
    "    plot_origin_heatmap,\n",
    "    plot_brand_supplier_bars,\n",
    "    summarize_cluster_tables,\n",
    ")\n",
    "\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3aaf1",
   "metadata": {},
   "source": [
    "## Step 1: Setting the Scope\n",
    "First we set the scope by filtering on Class2, Class3, Class4, Brand Name, Country of Origin, Group Supplier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple filtering (Class2, Class3, Class4, BrandName, CountryOfOrigin, GroupSupplier) ---\n",
    "from product_utils import (\n",
    "    filter_by_class2,\n",
    "    filter_by_class3,\n",
    "    filter_by_class4,\n",
    "    filter_by_brand_name,\n",
    "    filter_by_country_of_origin,   # NEW\n",
    "    filter_by_group_supplier,      # NEW\n",
    ")\n",
    "\n",
    "# 1) Configure filters (use None or [] to skip a filter)\n",
    "CLASS2 = [\"Fasteners\"]              # e.g. [\"Tractors\",\"Implements\"]\n",
    "CLASS3 = None                       # e.g. [\"Hydraulics\"]\n",
    "CLASS4 = None                       # e.g. [\"1234 - Filters\"]\n",
    "BRANDNAME = [\"Kramp\"]               # e.g. [\"Kramp\"]\n",
    "COUNTRYOFORIGIN = None              # e.g. [\"Germany\", \"PL\", \"CN\"]\n",
    "GROUPSUPPLIER = None                # e.g. [\"Kerbl Group\"]\n",
    "NEGATE = False                      # set True to invert selection\n",
    "\n",
    "# 2) Apply filters (only those provided)\n",
    "df_f = df.copy()\n",
    "\n",
    "if CLASS2:          df_f = filter_by_class2(df_f, CLASS2, negate=NEGATE)\n",
    "if CLASS3:          df_f = filter_by_class3(df_f, CLASS3, negate=NEGATE)\n",
    "if CLASS4:          df_f = filter_by_class4(df_f, CLASS4, negate=NEGATE)\n",
    "if BRANDNAME:       df_f = filter_by_brand_name(df_f, BRANDNAME, negate=NEGATE)\n",
    "if COUNTRYOFORIGIN: df_f = filter_by_country_of_origin(df_f, COUNTRYOFORIGIN, negate=NEGATE)\n",
    "if GROUPSUPPLIER:   df_f = filter_by_group_supplier(df_f, GROUPSUPPLIER, negate=NEGATE)\n",
    "\n",
    "print(f\"Rows after filtering: {len(df_f):,}\")\n",
    "df_f.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ðŸš€ Starting full clustering analysis pipeline...\")\n",
    "print(f\"   Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Step 1: Load data\n",
    "pipeline.load_data()\n",
    "\n",
    "# Step 2: Prepare features\n",
    "pipeline.prepare_features()\n",
    "\n",
    "# Step 3: Optimize clusters\n",
    "pipeline.optimize_clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23538d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_CLUSTERS = 5\n",
    "# Step 4: Run clustering methods\n",
    "if params.INCLUDE_KMEANS:\n",
    "    pipeline.run_kmeans_clustering(NUMBER_CLUSTERS)\n",
    "\n",
    "# if params.INCLUDE_HIERARCHICAL:\n",
    "#     pipeline.run_hierarchical_clustering(NUMBER_CLUSTERS)\n",
    "\n",
    "# Step 5: Compare methods\n",
    "pipeline.compare_clustering_methods()\n",
    "\n",
    "# Step 6: Generate visualizations\n",
    "if params.SHOW_VISUALIZATIONS:\n",
    "    pipeline.generate_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_METHOD = ['kmeans'] # ['kmeans', 'hierarchical', 'dbscan']\n",
    "# Step 7: Export results\n",
    "if params.EXPORT_RESULTS:\n",
    "    pipeline.export_results(methods=CHOSEN_METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed52520",
   "metadata": {},
   "source": [
    "# Step 2: Running Clustering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef33572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map products to clusters\n",
    "mapped_products = pipeline.clustering_results['kmeans']['df_clustered'][['ProductNumber', 'kmeans_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_params as P\n",
    "\n",
    "spec = P.feature_spec()\n",
    "# Build features from df:\n",
    "# - for each key in spec, combine columns in spec[key][\"from\"] using the chosen strategy.\n",
    "# - create df[feat_name] = ...\n",
    "X = df.copy()\n",
    "\n",
    "def _combine(cols, strategy=\"sum\"):\n",
    "    s = X[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    if strategy == \"latest\":\n",
    "        # pick the last non-null by year ordering\n",
    "        return s.ffill(axis=1).iloc[:, -1]\n",
    "    if strategy == \"mean\":\n",
    "        return s.mean(axis=1, skipna=True)\n",
    "    return s.sum(axis=1, skipna=True)  # default sum\n",
    "\n",
    "for feat_name, cfg in spec.items():\n",
    "    X[feat_name] = _combine(cfg[\"from\"], cfg[\"strategy\"])\n",
    "\n",
    "features = list(P.CLUSTER_FEATURES)  # [\"feat_purchase_amount_eur\", \"feat_quantity_sold\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
