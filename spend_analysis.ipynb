{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0bb1e1",
   "metadata": {},
   "source": [
    "# Part 1: Spend analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3371c38",
   "metadata": {},
   "source": [
    "### üì¶ Cell 1 ‚Äî Imports & prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c526606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from source.db_connect.bigquery_connector import BigQueryConnector\n",
    "from source.data_processing.analysis_utils import (\n",
    "    preprocess_detailed_data,\n",
    "    compute_abc_tiers,\n",
    "    fetch_purchase_data_enriched,\n",
    "    )\n",
    "from source.data_processing.normalization_utils import resolve_all, resolve_spend\n",
    "\n",
    "# Load data\n",
    "bq = BigQueryConnector()\n",
    "raw = fetch_purchase_data_enriched(bq)\n",
    "df = preprocess_detailed_data(raw)\n",
    "\n",
    "# Normalize / standardize all core columns (spend, class3, vendor, product identifiers)\n",
    "df = resolve_all(df)\n",
    "\n",
    "# Ensure spend column name\n",
    "SPEND_COL = 'total_spend'\n",
    "if SPEND_COL not in df.columns:\n",
    "    df, SPEND_COL = resolve_spend(df, spend_col=SPEND_COL)\n",
    "\n",
    "# Add ABC tiers\n",
    "df = compute_abc_tiers(df, spend_col=SPEND_COL, tier_col='abc_tier')\n",
    "\n",
    "# Analysis year inference\n",
    "if 'year' in df.columns:\n",
    "    YEAR = int(pd.to_numeric(df['year'], errors='coerce').dropna().mode().iloc[0])\n",
    "else:\n",
    "    YEAR = datetime.now().year\n",
    "\n",
    "print(f\"Rows: {len(df):,} | Cols: {len(df.columns)} | YEAR={YEAR}\")\n",
    "print('Columns:', df.columns.tolist())\n",
    "print(f\"Sample data:\\n{df.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f53ea",
   "metadata": {},
   "source": [
    "### üìàScatter: distribution of spend per Class3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679201e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: distribution of spend per Class3 (no year facet)\n",
    "work = df.copy()\n",
    "work[SPEND_COL] = pd.to_numeric(work[SPEND_COL], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Rank within each Class3 to spread points on X\n",
    "work[\"rank_in_class3\"] = work.groupby(\"Class3\")[SPEND_COL].rank(method=\"first\", ascending=False)\n",
    "\n",
    "# Legend ordering by total spend descending\n",
    "class3_spend = work.groupby(\"Class3\")[SPEND_COL].sum().sort_values(ascending=False)\n",
    "class3_order = class3_spend.index.tolist()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(\n",
    "    data=work,\n",
    "    x=\"rank_in_class3\",\n",
    "    y=SPEND_COL,\n",
    "    hue=\"Class3\",\n",
    "    hue_order=class3_order,\n",
    "    alpha=0.6,\n",
    "    s=25\n",
    ")\n",
    "plt.yscale(\"log\")  # heavy-tailed spend\n",
    "plt.title(\"Spend distribution per Class3 (log scale)\")\n",
    "plt.xlabel(\"Rank within Class3 (1 = highest spend)\")\n",
    "plt.ylabel(\"Spend\")\n",
    "plt.legend(title=\"Class3 (desc spend)\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: summary of product counts per Class3\n",
    "summary_counts = work.groupby(\"Class3\")[SPEND_COL].count().rename(\"product_count\").reset_index()\n",
    "print(\"Sample product counts per Class3:\")\n",
    "print(summary_counts.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d792fe",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è Cell 3 ‚Äî Scatter: distribution of spend by Group Vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "work = df.copy()\n",
    "work[SPEND_COL] = pd.to_numeric(work[SPEND_COL], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Limit legend noise: focus on top N vendors by total spend\n",
    "N_VENDORS = 10\n",
    "top_vendors = (work.groupby(\"GroupVendor\")[SPEND_COL]\n",
    "               .sum()\n",
    "               .sort_values(ascending=False)\n",
    "               .head(N_VENDORS)\n",
    "               .index)\n",
    "work[\"VendorTop\"] = np.where(work[\"GroupVendor\"].isin(top_vendors), work[\"GroupVendor\"], \"Other\")\n",
    "\n",
    "# Rank globally by spend\n",
    "work[\"rank_global\"] = work[SPEND_COL].rank(method=\"first\", ascending=False)\n",
    "\n",
    "# Legend ordering: VendorTop descending by total spend, keeping 'Other' last if present\n",
    "vendor_spend = work.groupby(\"VendorTop\")[SPEND_COL].sum().sort_values(ascending=False)\n",
    "vendor_order = [v for v in vendor_spend.index if v != \"Other\"] + ([\"Other\"] if \"Other\" in vendor_spend.index else [])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(\n",
    "    data=work,\n",
    "    x=\"rank_global\",\n",
    "    y=SPEND_COL,\n",
    "    hue=\"VendorTop\",\n",
    "    hue_order=vendor_order,\n",
    "    alpha=0.6,\n",
    "    s=25\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(f\"Spend distribution by Group Vendor (Top {N_VENDORS})\")\n",
    "plt.xlabel(\"Global rank (1 = highest spend)\")\n",
    "plt.ylabel(\"Spend\")\n",
    "plt.legend(title=\"GroupVendor (desc spend)\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19349109",
   "metadata": {},
   "source": [
    "### üßÆ Cell 4 ‚Äî Count of products by spend interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "work = df.copy()\n",
    "work[SPEND_COL] = pd.to_numeric(work[SPEND_COL], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Use log-spaced bins for heavy-tailed spend\n",
    "min_pos = max(work[SPEND_COL].replace(0, np.nan).min(), 1e-6)\n",
    "max_val = max(work[SPEND_COL].max(), 1)\n",
    "BINS = 15\n",
    "bins = np.geomspace(min_pos, max_val, BINS)\n",
    "\n",
    "work[\"spend_bin\"] = pd.cut(work[SPEND_COL].clip(lower=min_pos), bins=bins, include_lowest=True)\n",
    "counts = work[\"spend_bin\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "counts.plot(kind=\"bar\")\n",
    "plt.title(\"Count of products by spend interval (log-spaced bins)\")\n",
    "plt.xlabel(\"Spend interval (EUR)\")\n",
    "plt.ylabel(\"Count of products\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Optional) show a small table\n",
    "display(counts.to_frame(\"count\").head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703672fe",
   "metadata": {},
   "source": [
    "### ü§ñ Cell 5 ‚Äî Cluster products at Class3 level by purchase amount (EUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster products within each Class3 using spend column\n",
    "from source.data_processing.class3_analysis import cluster_products\n",
    "\n",
    "k = 3\n",
    "try:\n",
    "    df_class3_clusters = cluster_products(df, spend_col=SPEND_COL, k=k)\n",
    "    if df_class3_clusters.empty:\n",
    "        print(\"No clusters produced (empty after filtering).\")\n",
    "    else:\n",
    "        print(df_class3_clusters.head())\n",
    "except Exception as e:\n",
    "    print(\"Clustering failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1882705",
   "metadata": {},
   "source": [
    "### üì§ Cell 6 ‚Äî Export per Class3 to .xlsx with normalized columns and a top metadata row for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ba448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import source.data_processing.export_utils as export_utils\n",
    "\n",
    "# Reload to ensure latest function signature (after code edits)\n",
    "importlib.reload(export_utils)\n",
    "\n",
    "# Export with Level2 filter (e.g. 'Threaded Fasteners')\n",
    "LEVEL2_FILTER = [\"Threaded Fasteners\"]  # or any valid value\n",
    "output_dir_level2 = os.path.join(os.getcwd(), \"exports_per_class3_year_split_level2\")\n",
    "paths_level2 = export_utils.export_year_split_purchase_quantity(\n",
    "    bq,\n",
    "    output_dir_level2,\n",
    "    fmt_thousands=True,\n",
    "    segmentation_df=df,\n",
    "    segmentation_col=\"abc_tier\",\n",
    "    level2_filter=LEVEL2_FILTER\n",
    ")\n",
    "print({\"files_written\": len(paths_level2), \"output_dir\": output_dir_level2})\n",
    "\n",
    "# Export without Level2 filter (all data)\n",
    "output_dir_all = os.path.join(os.getcwd(), \"exports_per_class3_year_split\")\n",
    "paths_all = export_utils.export_year_split_purchase_quantity(\n",
    "    bq,\n",
    "    output_dir_all,\n",
    "    fmt_thousands=True,\n",
    "    segmentation_df=df,\n",
    "    segmentation_col=\"abc_tier\"\n",
    ")\n",
    "print({\"files_written\": len(paths_all), \"output_dir\": output_dir_all})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
